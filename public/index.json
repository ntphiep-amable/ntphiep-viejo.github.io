[{"content":"","date":"2023-11-22","permalink":"/tags/dagster/","section":"Tags","summary":"","title":"dagster"},{"content":"\rLời mở đầu # Bài viết đầu tiên của mình trên này, chủ yếu là dịch lại và thêm thắt chút từ hiểu biết, mong mọi người ủng hộ nhe 🥲😁\nI. Dagster là gì? # Dagster là một công cụ mã nguồn mở hỗ trợ Orchestrate Task (quản lý, tổ chức, điều phối và kiểm soát các tác vụ và công việc) . Nếu các bạn là Data Engineer hẳn sẽ phải biết Apache Airflow, về cơ bản mục đích sủ dụng của Dagster cũng giống như Airflow vậy (tuy nhiên chúng có nhiều điểm khác nhau, có thể mình sẽ viết một bài So sánh Airflow và Dagster). Nói chung, các công cụ trên hỗ trợ xây dựng data pipeline.\nDagster được xây dựng và phát triển bởi elementl. Trang web chính thức của Dagster: https://dagster.io/\nII. Ứng dụng và đặc điểm của Dagster # 1. Ứng dụng # Dagster là một công cụ mã nguồn mở, tập trung hỗ trợ Task Orchestrator. Dagster được thiết kế để phát triển và duy trì các data assets (ví dụ như Dataframe tables, các data sets, ML models, \u0026hellip;) Các data assets được sử dụng thông qua các function. Bạn khai báo các function và các data assets mà các fucntion đó tạo ra hoặc cập nhật. Sau đó ban sử dụng Dagster để chạy các fucntion đúng thời điểm và đảm bảo các assets luôn được cập nhật.\nDagster được sử dụng trong hầu như mọi giai đoạn của của vòng đời data development như local development, unit tests, integration tests, staging environments cho đến giai đoạn đưa lên production.\n2. Đặc điểm # Dagster sử dụng Python để hoạt động và có thể được cài đặt dễ dàng với Python pip (lưu ý Python version 3.8 trở lên). Để cài đặt Dagster cơ bản, chạy lênh sau trong terminal:\npip install dagster dagster-webserver Trong bài này chúng ta sẽ build một project đơn giản. Chúng ta collect dữ liệu từ một trang tổng hợp tin tức (ở đây là Hacker News), làm sạch nó và build một report đơn giản. Ta sẽ dùng Dagster để cập nhật data và report định kì, cái mà Dagster gọi là assets.\nTrước hết bạn cần hiểu về một khái niệm cốt lõi của Dagster, đó là Software-defined asset (SDA) . Một asset là một \u0026hellip; đối tượng trong bộ lưu trữ liên tục, cái mà có thể ghi lại một \u0026hellip; cái gì đó 😀😄 (lú vcl ~~ ). Cơ bản thì asset có thể là:\nMột table hoặc view trong database Một file (như file trên máy của bạn 😀) Một model Machine Learning Nếu bạn đã có một datap pipeline, bạn đã có những assets. Software-defined assets là một khái niệm cho bạn ghi data pipeline dựa trên các asset.\nDưới đây là một ví dụ. Một asset là một dataset tên là topstories, nó phụ thuộc vào một asset khác tên là topstory_ids. topstories lấy ID được tính toán trong topstory_ids, sau đó fetch data cho từng ID đó.\n@asset(deps=[topstory_ids]) def topstories() -\u0026gt; None: with open(\u0026#34;data/topstory_ids.json\u0026#34;, \u0026#34;r\u0026#34;) as f: topstory_ids = json.load(f) results = [] for item_id in topstory_ids: item = requests.get( f\u0026#34;https://hacker-news.firebaseio.com/v0/item/{item_id}.json\u0026#34; ).json() results.append(item) if len(results) % 20 == 0: print(f\u0026#34;Got {len(results)} items so far.\u0026#34;) df = pd.DataFrame(results) df.to_csv(\u0026#34;data/topstories.csv\u0026#34;) Một tập hợp các asset sẽ có dạng một đồ thị DAG (directed acyclic graph) (ai sử dụng Airflow sẽ phải biết cái này). Mỗi cạnh trong DAG tương ứng với sự phụ thuộc data giữa các asset. DAG giúp bạn:\nHiểu về sự liên quan giữa các asset. Giúp làm việc với data pipeline dễ dàng, hiệu quả hơn. Dagster có hỗ trợ giao diện người dùng (UI) dưới dạng web. Dưới dây là một DAG được biểu diễn trong User Interface: Lời kết # Trên đây là một số điều có bản các bạn cần biết về Dagster, chưa dài lắm cơ mà ngại viết 🤣, còn rất nhiều thứ về Dagster nhưng mình sẽ viết ở những bài sau (hoặc là không :)))). Bài tiếp theo có thể là một Sample project như đã nói ở trên nhé. Cảm ơn mọi người đã đọc!\nReferences # https://docs.dagster.io/getting-started\n","date":"2023-11-22","permalink":"/posts/dagster_1/","section":"Posts","summary":"Lời mở đầu # Bài viết đầu tiên của mình trên này, chủ yếu là dịch lại và thêm thắt chút từ hiểu biết, mong mọi người ủng hộ nhe 🥲😁","title":"Dagster Là Gì? Dagster Cơ Bản Cho Người Mới Bắt Đầu"},{"content":"","date":"2023-11-22","permalink":"/tags/data/","section":"Tags","summary":"","title":"data"},{"content":"","date":"2023-11-22","permalink":"/","section":"Hiep's blog","summary":"","title":"Hiep's blog"},{"content":"","date":"2023-11-22","permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":"2023-11-22","permalink":"/tags/python/","section":"Tags","summary":"","title":"python"},{"content":"","date":"2023-11-22","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"\r¡Hola a todos, soy Hiep! # Este es mi blog personal, aquí escribiré sobre temas como vida, programación, opiniones, emociones o temas varios\u0026hellip;\nGracias por leer😙.\nLói chung là cái cuộc sống này buồn ~\n¡Noviembre 2023, Hiep! # ","date":"2023-11-21","permalink":"/info/","section":"Hiep's blog","summary":"¡Hola a todos, soy Hiep! # Este es mi blog personal, aquí escribiré sobre temas como vida, programación, opiniones, emociones o temas varios\u0026hellip;\nGracias por leer😙.\nLói chung là cái cuộc sống này buồn ~","title":"About NTPH"},{"content":"","date":"2023-11-21","permalink":"/tags/shop/","section":"Tags","summary":"","title":"shop"},{"content":"\rThis is my shopp # ","date":"2023-11-21","permalink":"/shop/","section":"Hiep's blog","summary":"\rThis is my shopp # ","title":"Shop"},{"content":"\rLời mở đầu # Ở bài trước - Giới thiệu DBT - mình đã đề cập đến việc dùng dbt kết nối và làm việc với các data platform khác. Hôm nay mình sẽ kết nối đến và thực hiện một vài thao tác cơ bản đến Google Big Query - một trong những Data platform phổ biến nhất thời điểm hiện tại.\nTrong bài, mình sẽ dùng một dataset mẫu để mô phỏng quá trình. Dataset tên là jaffle_shop. Nếu bạn thực hành với dataset khác, thao tác tương tự 🥲.\nCác setup cần thiết # Để có thể sử dụng một công cụ nào đó, đương nhiên là trước tiên bạn phải cài đặt rồi 😄\nVới dbt, mình đã hướng dẫn cài dbt ở bài trước, dùng pip đơn giản: pip install dbt-core dbt-bigquery Sau đó, kiểm tra lại với lệnh:\ndbt --version Với Big query, mình sẽ nói ngắn gọn các thao tác cần thiết, chi tiết các bạn có thể tìm đọc các trang hướng dẫn Big Query cơ bản\u0026hellip; Trước hết, bạn cần phải có tài khoản Google trước, sau đó truy cập BigQuery Console, tạo một project mới đặt tên gì cũng được. Sau đó, hãy thử với câu query cơ bản sau khi tạo project: select * from `dbt-tutorial.jaffle_shop.customers`; Nếu không có gì sai thì result sẽ như sau: Sau khi thử chạy thành công trên console của Big query, hãy tạo một dataset mới (\rhướng dẫn), ở đây mình đặt là jaffle_shop. Ai đã làm việc với Big query sẽ biết dataset tương đương với database hoặc schema trong các hệ cơ sở dữ liệu cơ bản. Các bước tiếp theo là Tạo Credential Trong Big query, cuối cùng là download keyfile dạng JSON về. Keyfile JSON có format như sau:\n{ \u0026#34;type\u0026#34;: \u0026#34;service_account\u0026#34;, \u0026#34;project_id\u0026#34;: \u0026#34;PROJECT_ID\u0026#34;, \u0026#34;private_key_id\u0026#34;: \u0026#34;KEY_ID\u0026#34;, \u0026#34;private_key\u0026#34;: \u0026#34;-----BEGIN PRIVATE KEY-----\\nPRIVATE_KEY\\n-----END PRIVATE KEY-----\\n\u0026#34;, \u0026#34;client_email\u0026#34;: \u0026#34;SERVICE_ACCOUNT_EMAIL\u0026#34;, \u0026#34;client_id\u0026#34;: \u0026#34;CLIENT_ID\u0026#34;, \u0026#34;auth_uri\u0026#34;: \u0026#34;https://accounts.google.com/o/oauth2/auth\u0026#34;, \u0026#34;token_uri\u0026#34;: \u0026#34;https://accounts.google.com/o/oauth2/token\u0026#34;, \u0026#34;auth_provider_x509_cert_url\u0026#34;: \u0026#34;https://www.googleapis.com/oauth2/v1/certs\u0026#34;, \u0026#34;client_x509_cert_url\u0026#34;: \u0026#34;https://www.googleapis.com/robot/v1/metadata/x509/SERVICE_ACCOUNT_EMAIL\u0026#34; } Vậy là OK phần setup chuẩn bị các thứ rồi 😁, giờ hãy đến phần chính nào!\nKết nối dbt đến Big query # Tạo project với dbt # Di chuyển đến thư mục bạn muốn tạo project, chạy lệnh sau:\ndbt init jaffle_shop Như đã nói, mình sẽ lấy tên project là jaffle_sshop, bạn có thể đặt tên khác tùy ý. Hãy mở project vừa tạo lên, ở đây mình sử dụng VS-Code. Bạn sẽ thấy những file và folder được tạo trong thư mục project, mỗi file và folder đảm nhận chức năng khác nhau và cần thiết cho project.\nÝ nghĩa các file và folder trong thư mục project # analyses: thư mục hỗ trợ tổ chức các truy vấn SQL phân tích trong dự án, chứa các script sql mà analytic cần, cơ mà nó chỉ compile chứ không có excute. macros: chứa các block code có thể tái sử dụng nhiều lần, tiện lợi đỡ phí thời gian, viết 1 lần rồi thích gọi ở đâu cũng được. models: là thư mục quan trọng nhất của project, đơn giản bởi vì nó là folder chứa các model :))). Mỗi file .sql trong folder này là một model (có thể là table, view, \u0026hellip;). Khi chạy dbt run sẽ tự generate model và insert data. seeds: chứa các file .csv, static data, giúp load data từ file vào các data platform thuận tiện hơn. snapshots: giúp chứa snapshot data của một table tại một thời điểm nào đó nếu dữ liệu các bảng có thể bị thay đổi. tests: đơn giản như cái tên 😀, chứa các query bạn dùng để test các model và resource. Khi chạy dbt test sẽ giúp bạn test tự động. dbt_project.yml: file config quan trọng không thể thiếu của project, chứa các thông tin như name, version, profile, path, vars, \u0026hellip; cần thiết cho chạy dự án. Tạm thời khi mới khởi tạo project thì chỉ có vậy, nhưng sau khi bạn thực hiện kết nối, sẽ có thêm vài file và folder sinh ra thêm như seed, logs, target, \u0026hellip; Cơ mà lười giải thích nên để sau nhé 😌\nThực hiện kết nối # DBT sẽ thực hiện kết nối đến Data warehouse sử dụng profile. Nó được định nghĩa trong một file gọi là profiles.yml, trong đó chứa tất cả các thông tin chi tiết cần thiết để thực hiện kết nối đến data warehouse. Ở thư mục ~/.dbt (nếu là linux) hoặc C:\\Users\\Username\\.dbt (nếu là windows), bạn hãy tạo file profiles.yml. Sau đó, hãy copy file JSON chứa key đã tải ở phần trên vào cùng thư mục này, tiếp theo hãy copy và sửa các giá trị cho phù hợp.\njaffle_shop: # this needs to match the profile in your dbt_project.yml file target: dev outputs: dev: type: bigquery method: service-account keyfile: # replace this with the full path to your keyfile project: # Replace this with your project id dataset: # Replace this with dbt_your_name threads: 1 timeout_seconds: 300 location: US priority: interactive Note: Tại sao lại để profiles.yml ngoài thư mục project? Đó là bởi vì lý do hạn chế các sensitive credentials(các thông tin nhạy cảm) bị check bởi các công cụ version control. Thực ra thì bạn có thể để chung với thư mục project cũng được với điều kiện là nên sử dụng các environment variables (biến môi trường) để load các sensitive credentials. Còn nếu để ngoài thì dbt sẽ tự động tìm trong thư mục ~/.dbt. Ô cê, cuối cùng hãy vào thư mục chứa project và chạy:\ndbt debug Và nếu kết quả hiển thị như lày là bạn đã kết nối thành công rồi!!\nConnection test: OK connection ok Vậy là thành công kết nối dbt đến Big Query rồi, các bạn có thể thực hiện các công việc như build model, load data, chạy test, schedule jobs, \u0026hellip;Có thể mình sẽ hướng dẫn ở những bài tiếp theo. Rất đơn giản phải khum 😉. Chúc các bạn kết nối thành công nhé!\nReference # https://docs.getdbt.com/quickstarts/manual-install?step=1\nhttps://docs.getdbt.com/quickstarts/bigquery?step=1\n","date":"2023-09-25","permalink":"/posts/dbt_2/","section":"Posts","summary":"Lời mở đầu # Ở bài trước - Giới thiệu DBT - mình đã đề cập đến việc dùng dbt kết nối và làm việc với các data platform khác.","title":"[DBT] Kết Nối DBT Với Big Query"},{"content":"","date":"2023-09-25","permalink":"/tags/bigquerry/","section":"Tags","summary":"","title":"bigquerry"},{"content":"","date":"2023-09-25","permalink":"/tags/dbt/","section":"Tags","summary":"","title":"dbt"},{"content":"\rLời mở đầu # Các bạn DE, DA khi tìm search từ khóa \u0026ldquo;dbt\u0026rdquo; trên Google thường sẽ ra nhiều kết quả khác nhau về những cụm từ có viết tắt là \u0026ldquo;dbt\u0026rdquo;, và không may thay là cái mà DE, DA cần lại thường không được suggest đầu tiên :))). Cái mình nhắc đến hôm nay là Data Build Tool, một công cụ mã nguồn mở hỗ trợ chủ yếu việc transform data. Dạo gần đây thấy nó nổi lên khá là mạnh và được sử dụng tương đối nhiều.\nI. DBT là gì? # Đối với các bạn DA, muốn xây dựng một BI Model, việc module hóa quá trình transform data là thực sự cần thiết. Có rất nhiều tool hỗ trợ transform mạnh mẽ có thể kể đến như Pandas (python), Apache Spark, R, Apache Nifi, \u0026hellip;.. Tuy nhiên để có thể dễ dàng sử dụng cho các bạn đã biết SQL thì dbt là một lựa chọn rất tốt vì nó hỗ trợ module hóa các câu lệnh SQL, vậy nên các bạn chỉ cần có nền tảng SQL có thể dễ dàng sử dụng.\nNhư đã lói, nó là một tool open-source được xây dựng và phát triển bởi RJMetrics vào năm 2016. Mục đích ban đầu và cũng là mục đích chính của dbt là transform data. Data build tool sủ dụng SQL dó đó quá trình transform trở nên nhanh và dễ dàng hơn.\nĐiều làm dbt trở nên đặc biệt là dbt có thể giúp một Analyst bình thường có thể thực hiện được những công việc cơ bản của Engineer (chủ yếu là transform - biến đổi dữ liệu). DBT giúp việc transform, document, test data trở nên dễ dàng hơn và có thể nhân rộng được. Thực hiện các điều trên cũng trở nên đơn giản hơn thông qua việc sử dụng các công cụ của dbt chứ bạn không cần phải set up hệ thống test và viết document tách biệt.\nNguồn: https://www.getdbt.com/product/what-is-dbt/\nII. Các điểm nổi bật của dbt # Lý do dbt được lựa chọn trong việc transform dữ liệu cho cả những người mới và trong cả các công ty là bởi dbt có rất nhiều tính năng hay ho. Dưới đây mình sẽ liệt kê một vài tính năng và công cụ rất tiện lợi mà dbt cung cấp:\n1. Rút gọn boilerplate (đoạn code mang tính hình thức) # Mỗi DBMS (hệ quản trị cơ sở dữ liệu) sẽ sủ dụng một loại SQL khác nhau. Ví dụ như Oracle sử dụng PL-SQL trong khi Microsoft SQL Server sử dụng T-SQL, \u0026hellip;. Cơ bản thì nó vẫn là SQL tuy nhiên mỗi loại lại có những có pháp, cách sủ dụng có phần khác nhau không nhiều thì ít, kiểu như có loại sẽ dùng LIMIT, có loại dùng TOP, có loại dùng kiểu STRING có loại lại là VARCHAR, db có gốc Java thì có kiểu DOUBLE còn mấy cái khác thì không v.v\u0026hellip;.\nCũng vì lý do này mà không mấy ai thích việc phải viết và define từng table, column hay insert data vào database trực tiếp bằng SQL ( thậm chí developer còn tránh làm điều này mà dùng ORM để thay thế 🙃). DBT sinh ra để một phần cải thiện vấn đề này. Nó giúp lược bỏ những đoạn code mang tính hình thức. Điều này có thể giúp bạn thao tác tốt hơn với các table với số lượng lớn và phụ thuộc vào nhau.\nVí dụ bạn có một table tên customer, bạn muốn tạo một bảng mới tên là person với một số cột từ bảng customer, với SQL bình thường thì phải làm như sau:\nDROP TABLE IF EXISTS person; CREATE TABLE person AS ( SELECT ID, FirstName, LastName, City, Address FROM customer; ) Còn với dbt, bạn chỉ cần viết:\nSELECT ID, FirstName, LastName, City, Address FROM customer Và lưu lại với file tên person.sql, đơn giản và nhanh gọn là bạn đẫ có table tên person, đầy đủ data y hệt như khi viết SQL bình thường. Ở một ví dụ nhỏ như thế này chúng ta có thể thấy sự khác biệt không nhiều, nhưng trên thực tế rất có ích với quy mô hàng trăm tables cùng 1 lúc và phụ thuộc vào nhau.\n2. Hỗ trợ đa dạng Data Platform - Data Warehouse # DBT hỗ trợ kết nối và làm việc cùng với rất đa dạng các Data Platform khác nhau. Dưới đây là một số những data platform phổ biến mà dbt có thể kết nối và làm việc.\nNguồn: https://docs.getdbt.com/docs/supported-data-platforms\nĐối với mỗi data platfom mà bạn muốn làm việc, cần cài đặt 2 thư viện là dbt-core và thư viện tương ứng với platform đó. Ví dụ nếu muốn làm việc với Google BigQuery thì cài dbt-bigquery nữa là được\npip install dbt-core dbt-bigquery 3. Models hóa abstraction và dependency # Các table trong một database có một abstract dependency ( Tạm gọi là sự lệ thuộc ảo ) với nhau. Khi chạy SQL thông qua dbt, thì các câu SQL sẽ được chạy theo tuần tự như dependency đã được khởi tạo trong dbt-models.\n4. Data Lineage và documentation # Thêm nữa, dbt còn cung cấp công cụ document, khi bạn tạo ra dependency, dbt sẽ tự động tạo ra các tài liệu để biểu thị sự phụ thuộc giữa các model. Bạn sẽ không cần phải tự ghi tài liệu mà vẫn có tài liệu để nắm rõ nguồn gốc và mối liên hệ của data. Khá là tiện lợi!!\nNgoài việc có đồ thị cho data lineage, dbt còn hỗ trợ tự động tạo tài liệu cho data. Bạn có thể ghi lại ý nghĩa của từng column, table do bạn tạo ra (tương tự Metadata đã nhắc tới trong Dagster, tránh trường hợp sau này quên mất chúng là gì.\n5. Hỗ trợ Jinja template # Jinja là một template engine rất nổi tiếng, ai làm Front-End web chắc hẳn đã nghe qua và sử dụng. Trong trường hợp của dbt, nó sẽ giúp bạn thu gọn những câu lệnh SQL rất dài thành ngắn lại. Ví dụ như sau đây:\nselect * from {{ ref(\u0026#39;my_first_dbt_model\u0026#39;) }} where id = 1 Ở đây thay vì các bạn phải ghi chi tiết từ database đến table \u0026hellip;. để kết nối tới table my_first_dbt_model thì các bạn chỉ cần ghi ngắn gọn lại như vậy và dbt sẽ xử lý đầy đủ.\n6. Test tự động # DBT có rất nhiều loại test tự động khác nhau được soạn sẵn, hoặc bạn có thể tự viết bằng dbt macros. Như vậy bạn có thể chuẩn hóa quy trình bằng cách yêu cầu tất cả models pass các test được đề ra mà không cần phải check thủ công từng table.\n7. Có nền tảng Cloud # DBT có 2 bản Cloud và CLI, bản Cloud có giao diện rất đẹp cùng nhiều tính năng tiện lợi hay ho hơn bản CLI nhiều, và đương nhiên là mất phí rồi :)))\nLời kết # Cơ bản thì không có một công cụ nào là hoàn hảo về mọi măt. DBT cũng chỉ là một lựa chọn trong số rất nhiều công cụ khác. Trong một dự án phải sử dụng kết hợp nhiều công cụ mới có thể tối uu điểm mạnh. Tuy nhên DBT cũng là một công cụ khá hay ho mà các bạn nên trai nghiệm vì một phần nó không khó để bắt đầu và cũng vì nó đang dần trở nên phổ biến thời gian gần đây. Bài viết mình tổng hợp từ vài nguồn và hiểu biết, thiếu sót mong mọi người góp ý. Cảm ơn mọi người đã đọc!\nReference # https://tuananalytic.com/dbt-data-build-tool-la-gi/\nhttps://www.getdbt.com/\nhttps://www.getdbt.com/product/what-is-dbt/\n","date":"2023-08-05","permalink":"/posts/dbt_1/","section":"Posts","summary":"Lời mở đầu # Các bạn DE, DA khi tìm search từ khóa \u0026ldquo;dbt\u0026rdquo; trên Google thường sẽ ra nhiều kết quả khác nhau về những cụm từ có viết tắt là \u0026ldquo;dbt\u0026rdquo;, và không may thay là cái mà DE, DA cần lại thường không được suggest đầu tiên :))).","title":"DBT (Data Build Tool) Là Gì? Những Thứ Cơ Bản Về DBT"},{"content":"","date":"2023-08-05","permalink":"/tags/etl/","section":"Tags","summary":"","title":"etl"},{"content":"\rLời mở đầu # Trong bài trước mình đã giới thiệu với mọi người về Dagster, nó là gì, dùng để làm gì. Trong bài này mình sẽ hướng dẫn các bạn làm một project cơ bản với Dagster, cụ thể là build một data pipeline đơn giản. Ai quên thì kệ 🤪!\nI. Cài đặt thư viện và các thứ cần thiết # Để cài Dagster, bạn cần phải cài đặt Python bản 3.8 trở lên, sau đó có thể cài Dagster rất dễ dàng thông qua pip. Mở termianl và chạy câu lệnh sau:\npip install dagster dagster-webserver dagit Vậy là bạn đã có thể cài Dagster với chỉ thao tác đơn giản. Bạn cũng có thể cài Dagster thông qua source của nó, cơ mà cái nào đơn giản thì làm :))\nII. Định nghĩa các asset # Trong bài trước, chúng ta đã tìm hiểu asset là gì, tuy nhiên với một cách khá là lý thuyết. Hôm nay mình sẽ cho các bạn thấy asset thực sự là gì, cách implement nó trong code và trực quan của nó trông ra sao.\nNhư đã nói ở bài trước, chúng ta sẽ tạo một project cơ bản để build một data pipeline với các giai đoạn:\nDownloads top 10 stories từ HackerNews Tiến hành lọc và chọn ra các field cần thiết Ghi kết quả thu được vào Pandas Dataframe rồi cuối cùng lưu xuống file .csv Mình đang sử dụng Ubuntu. Tạo một folder tên gì cũng được :)) ở đây mình đặt tên là hello-dagster, di chuyển vào folder và tạo một file Python, ở đây mình đặt là hello-dagster.py.\nmkdir hello-dagster cd hello-dagster touch hello-dagster.py Code trong file hello-dagster.py:\nimport json import requests import pandas as pd from dagster import AssetExecutionContext, MetadataValue, asset @asset def hackernews_top_story_ids(): \u0026#34;\u0026#34;\u0026#34; Get top 10 stories from the HackerNews top stories endpoint. API Docs: https://github.com/HackerNews/API#new-top-and-best-stories. \u0026#34;\u0026#34;\u0026#34; top_story_ids = requests.get(\u0026#34;https://hacker-news.firebaseio.com/v0/topstories.json\u0026#34;).json() with open(\u0026#34;hackernews_top_story_ids.json\u0026#34;, \u0026#34;w\u0026#34;) as f: json.dump(top_story_ids[:10], f) # asset dependencies can be inferred from parameter names @asset(deps=[hackernews_top_story_ids]) def hackernews_top_stories(context: AssetExecutionContext): \u0026#34;\u0026#34;\u0026#34;Get items based on story ids from the HackerNews items endpoint.\u0026#34;\u0026#34;\u0026#34; with open(\u0026#34;hackernews_top_story_ids.json\u0026#34;, \u0026#34;r\u0026#34;) as f: hackernews_top_story_ids = json.load(f) results = [] for item_id in hackernews_top_story_ids: item = requests.get(f\u0026#34;https://hacker-news.firebaseio.com/v0/item/{item_id}.json\u0026#34;).json() results.append(item) df = pd.DataFrame(results) df.to_csv(\u0026#34;hackernews_top_stories.csv\u0026#34;) # recorded metadata can be customized metadata = { \u0026#34;num_records\u0026#34;: len(df), \u0026#34;preview\u0026#34;: MetadataValue.md(df[[\u0026#34;title\u0026#34;, \u0026#34;by\u0026#34;, \u0026#34;url\u0026#34;]].to_markdown()), } context.add_output_metadata(metadata=metadata) Ở đoạn code trên, chúng ta define 2 function, function đầu tiên là hackernews_top_story_ids có nhiệm vụ fetch data (ID của các story) từ API của Hacker News, sau đó lưu vào file dưới dạng JSON, sau đó function thứ 2 là hackernews_top_stories sẽ đọc dữ liệu từ file JSON vừa lưu, sau đó tiếp tục collect data (dựa trên iD vừa thu được) và lưu vào một Pandas Dataframe. Đoạn code chức năng trong 2 hàm cũng dễ hiểu nên k cần giải thích gì nhỉ :)))\nVà bước quan trọng tiếp theo là thêm decorator @asset cho mỗi function. Và từ đó chúng ta đã có 2 assets lần lượt là hackernews_top_story_ids và hackernews_top_stoies. Ở decorator của function hackernews_top_stories có tham số deps, có nghĩa là asset hackernews_top_stoies phụ thuộc vào asset hackernews_top_story_ids (phải có ID của story mới lấy được story và các thông tin khác). Ô cê cũng dễ nhỉ 😁\nIII. Chạy UI cho trực quan thôi ~~ # Từ từ, hãy đảm bảo bạn đã install cả Pandas nữa :)))\npip install pandas Ô cê rồi, di chuyển đển thư mục chứa hello-dagster.py và chạy lệnh sau:\ndagster dev -f hello-dagster.py Lệnh này sẽ khởi động web server đến host Dagster\u0026rsquo;s UI. Vậy là chúng ta đã thành công khởi động Dagster UI. Mặc định sẽ chạy ở cổng 3000 (có thể đổi cổng bằng option -p khi chạy command). Truy cập vào http://localhost:3000/ và web server sẽ hiển thị.\nVà các bạn đã có thể thấy được UI của Dagster với 2 asset được hiển thị. Mũi tên từ hackernews_top_story_ids đến hackernews_top_stoies Bấm vào nút Materialize All là các bạn có thể chạy thành công pipeline rồi. Data sẽ được collect về và lưu vào file JSON.\nNhưng vẫn còn một thứ khá hay ho, đó là Metadata. Thông tin của asset sẽ được lưu trong metadata. Ở trong hàm hackernews_top_stories ta đã định nghĩa metadata và lưu các thông tin cơ bản của asset trong đó. Ở webserver, ta có thể truy cập và xem thông tin metadata bằng cách click vào asset, sau đó click vào [Show Markdown] ở phần Materialization in Last Run\nVà kết quả sẽ hiển thị như sau:\nLời kết # Ô cê vậy là mình đã hướng dẫn các bạn build và chạy một cái pipeline đơn giản đầu tiên với Dagster. Những bài sau tiếp tục là kiến thức với Dagster nhé. Cảm ơn mọi người đã đọc!\nReference # https://docs.dagster.io/getting-started/hello-dagster\n","date":"2023-08-01","permalink":"/posts/dagster_2/","section":"Posts","summary":"Lời mở đầu # Trong bài trước mình đã giới thiệu với mọi người về Dagster, nó là gì, dùng để làm gì. Trong bài này mình sẽ hướng dẫn các bạn làm một project cơ bản với Dagster, cụ thể là build một data pipeline đơn giản.","title":"Dagster Cơ Bản: Build Một Data Pipeline Đơn Giản Với Dagster"},{"content":"","date":"2023-08-01","permalink":"/tags/data-pipeline/","section":"Tags","summary":"","title":"data pipeline"},{"content":"Day moi la about ne\n","date":"0001-01-01","permalink":"/about/","section":"Hiep's blog","summary":"Day moi la about ne","title":""},{"content":"","date":"0001-01-01","permalink":"/authors/","section":"Authors","summary":"","title":"Authors"},{"content":"","date":"0001-01-01","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"0001-01-01","permalink":"/series/","section":"Series","summary":"","title":"Series"}]